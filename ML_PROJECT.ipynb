{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import collections as cls\n",
    "from sklearn.metrics import f1_score,make_scorer\n",
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9767186470459038\n"
     ]
    }
   ],
   "source": [
    "## check the distribution of the y\n",
    "print(np.sum(train['LEAVE'] == 1)/np.sum(train['LEAVE'] == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------COLLEGE---------\n",
      "one     50.4333\n",
      "zero    49.5667\n",
      "Name: COLLEGE, dtype: float64\n",
      "-----------REPORTED_SATISFACTION---------\n",
      "very_unsat    39.7722\n",
      "very_sat      25.2111\n",
      "unsat         19.8278\n",
      "avg           10.0444\n",
      "sat            5.1444\n",
      "Name: REPORTED_SATISFACTION, dtype: float64\n",
      "-----------REPORTED_USAGE_LEVEL---------\n",
      "little         39.3444\n",
      "very_high      25.5333\n",
      "very_little    20.1111\n",
      "high           10.0500\n",
      "avg             4.9611\n",
      "Name: REPORTED_USAGE_LEVEL, dtype: float64\n",
      "-----------CONSIDERING_CHANGE_OF_PLAN---------\n",
      "considering                 39.9278\n",
      "actively_looking_into_it    24.8333\n",
      "no                          20.2333\n",
      "never_thought                9.8167\n",
      "perhaps                      5.1889\n",
      "Name: CONSIDERING_CHANGE_OF_PLAN, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COLLEGE</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>OVERAGE</th>\n",
       "      <th>LEFTOVER</th>\n",
       "      <th>HOUSE</th>\n",
       "      <th>HANDSET_PRICE</th>\n",
       "      <th>OVER_15MINS_CALLS_PER_MONTH</th>\n",
       "      <th>AVERAGE_CALL_DURATION</th>\n",
       "      <th>REPORTED_SATISFACTION</th>\n",
       "      <th>REPORTED_USAGE_LEVEL</th>\n",
       "      <th>CONSIDERING_CHANGE_OF_PLAN</th>\n",
       "      <th>LEAVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zero</td>\n",
       "      <td>28987</td>\n",
       "      <td>191</td>\n",
       "      <td>20</td>\n",
       "      <td>175953</td>\n",
       "      <td>217</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>unsat</td>\n",
       "      <td>very_little</td>\n",
       "      <td>considering</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zero</td>\n",
       "      <td>45201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>841177</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>unsat</td>\n",
       "      <td>avg</td>\n",
       "      <td>actively_looking_into_it</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>110663</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>902611</td>\n",
       "      <td>529</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>very_unsat</td>\n",
       "      <td>high</td>\n",
       "      <td>perhaps</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zero</td>\n",
       "      <td>40646</td>\n",
       "      <td>169</td>\n",
       "      <td>71</td>\n",
       "      <td>772903</td>\n",
       "      <td>146</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>very_unsat</td>\n",
       "      <td>little</td>\n",
       "      <td>considering</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one</td>\n",
       "      <td>132530</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>196535</td>\n",
       "      <td>559</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>very_unsat</td>\n",
       "      <td>avg</td>\n",
       "      <td>perhaps</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zero</td>\n",
       "      <td>69391</td>\n",
       "      <td>48</td>\n",
       "      <td>18</td>\n",
       "      <td>431255</td>\n",
       "      <td>290</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>very_unsat</td>\n",
       "      <td>very_high</td>\n",
       "      <td>never_thought</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>one</td>\n",
       "      <td>27400</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>277793</td>\n",
       "      <td>334</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>unsat</td>\n",
       "      <td>very_little</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>one</td>\n",
       "      <td>149672</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>315684</td>\n",
       "      <td>708</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>very_unsat</td>\n",
       "      <td>very_high</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>one</td>\n",
       "      <td>84477</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>649511</td>\n",
       "      <td>260</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>very_unsat</td>\n",
       "      <td>high</td>\n",
       "      <td>perhaps</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>one</td>\n",
       "      <td>157543</td>\n",
       "      <td>209</td>\n",
       "      <td>10</td>\n",
       "      <td>272756</td>\n",
       "      <td>862</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>unsat</td>\n",
       "      <td>very_high</td>\n",
       "      <td>perhaps</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  COLLEGE  INCOME  OVERAGE  LEFTOVER   HOUSE  HANDSET_PRICE  \\\n",
       "0    zero   28987      191        20  175953            217   \n",
       "1    zero   45201        0         0  841177            160   \n",
       "2     one  110663        0         0  902611            529   \n",
       "3    zero   40646      169        71  772903            146   \n",
       "4     one  132530        0        10  196535            559   \n",
       "5    zero   69391       48        18  431255            290   \n",
       "6     one   27400      198         0  277793            334   \n",
       "7     one  149672       29         7  315684            708   \n",
       "8     one   84477        0        10  649511            260   \n",
       "9     one  157543      209        10  272756            862   \n",
       "\n",
       "   OVER_15MINS_CALLS_PER_MONTH  AVERAGE_CALL_DURATION REPORTED_SATISFACTION  \\\n",
       "0                           28                      5                 unsat   \n",
       "1                            1                     15                 unsat   \n",
       "2                            1                     13            very_unsat   \n",
       "3                           24                      2            very_unsat   \n",
       "4                            0                      6            very_unsat   \n",
       "5                            3                      4            very_unsat   \n",
       "6                           29                     10                 unsat   \n",
       "7                            4                      4            very_unsat   \n",
       "8                            1                      5            very_unsat   \n",
       "9                            3                      5                 unsat   \n",
       "\n",
       "  REPORTED_USAGE_LEVEL CONSIDERING_CHANGE_OF_PLAN  LEAVE  \n",
       "0          very_little                considering      1  \n",
       "1                  avg   actively_looking_into_it      0  \n",
       "2                 high                    perhaps      0  \n",
       "3               little                considering      1  \n",
       "4                  avg                    perhaps      0  \n",
       "5            very_high              never_thought      0  \n",
       "6          very_little                         no      1  \n",
       "7            very_high                         no      1  \n",
       "8                 high                    perhaps      0  \n",
       "9            very_high                    perhaps      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check the distribution of the categorical variables\n",
    "for c in train[['COLLEGE','REPORTED_SATISFACTION','REPORTED_USAGE_LEVEL','CONSIDERING_CHANGE_OF_PLAN']].columns:\n",
    "               print(\"-----------{}---------\".format(c))\n",
    "               print(round(train[c].value_counts()/len(train)*100,4))\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "lb_make = LabelEncoder()\n",
    "train[\"REPORTED_USAGE_LEVEL\"] = lb_make.fit_transform(train[\"REPORTED_USAGE_LEVEL\"])\n",
    "train[\"CONSIDERING_CHANGE_OF_PLAN\"] = lb_make.fit_transform(train[\"CONSIDERING_CHANGE_OF_PLAN\"])\n",
    "train[\"COLLEGE\"] = lb_make.fit_transform(train[\"COLLEGE\"])\n",
    "train[\"REPORTED_SATISFACTION\"] = lb_make.fit_transform(train[\"REPORTED_SATISFACTION\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill NA\n",
    "train = train.fillna(train.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9.73456794e-01, 2.65427501e-02, 3.31121575e-07, 1.13225138e-07,\n",
       "       1.11340688e-08, 4.88914248e-10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PCA\n",
    "pca = PCA(n_components=6)\n",
    "xnames = train.columns.values.tolist()[:11]\n",
    "\n",
    "Xtr = np.array(train[xnames])\n",
    "ytr = np.array(train[['LEAVE']])\n",
    "\n",
    "# Xtrs = preprocessing.scale(Xtr)\n",
    "\n",
    "Xtrs = pca.fit_transform(Xtr)\n",
    "print(Xtrs.shape)\n",
    "\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimator(Use Logistic Regression )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc = 0.6955\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "nfold = 10\n",
    "kf = KFold(n_splits=nfold, shuffle=True)\n",
    "auc = []\n",
    "for train, test in kf.split(Xtrs):\n",
    "    Xtr_split = Xtrs[train,:]\n",
    "    ytr_split = ytr[train]\n",
    "    Xts_split = Xtrs[test,:]\n",
    "    yts_split = ytr[test]\n",
    "    logreg = linear_model.LogisticRegression(C=1e5)\n",
    "    logreg.fit(Xtr_split,ytr_split)\n",
    "    yhat = logreg.predict(Xts_split)\n",
    "    yprob = logreg.predict_proba(Xts_split)\n",
    "    auci = metrics.roc_auc_score(yts_split, yprob[:, 1])\n",
    "    auc.append(auci)\n",
    "aucm = np.mean(auc)\n",
    "print('auc = {0:.4f}'.format(aucm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimator(Use Random Forest )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600], 'max_depth': [7, 8, 9, 10, 11, 12, 13]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(f1_score, average=micro), verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.ensemble as kn\n",
    "rf=kn.RandomForestClassifier()\n",
    "tree_num=[50,100,150,200,250,300,350,400,450,500,550,600]\n",
    "max_depth=[7,8,9,10,11,12,13]\n",
    "parameters ={'n_estimators':tree_num,'max_depth':max_depth}\n",
    "f1 = make_scorer(f1_score, average='micro')\n",
    "clf = GridSearchCV(rf,parameters,cv=5,scoring=f1)\n",
    "clf.fit(Xtrs,ytr.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=600, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 8, 'n_estimators': 600}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7047222222222222"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = kn.RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=600, n_jobs=None,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4998612839506173\n",
      "0.8316319779864773\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "best_model.fit(Xtrs,ytr.ravel())\n",
    "yhat = best_model.predict(Xtrs)\n",
    "print(np.mean(yhat == ytr))\n",
    "yprob = best_model.predict_proba(Xtrs)\n",
    "auc = metrics.roc_auc_score(ytr, yprob[:, 1])\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimator(Use XGBClassifier )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To Find the Best Parameters of XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Procedure to adjust the parameters of xgboost\n",
    "\n",
    "\n",
    "# xtr,xts,ytr,yts = train_test_split(Xtrs, ytr, test_size=0.33)\n",
    "# parameters ={'n_estimators':[85,88,90,93,95]}\n",
    "# gsearch = GridSearchCV(XGBClassifier(learning_rate=0.05),parameters,cv=5,scoring='roc_auc')\n",
    "# gsearch.fit(xtr,np.array(ytr).ravel())\n",
    "# print(gsearch.best_params_)\n",
    "\n",
    "# xtr,xts,ytr,yts = train_test_split(Xtrs, ytr, test_size=0.33)\n",
    "# parameters ={'max_depth':range(3,10,2), 'min_child_weight':range(1,6,2),}\n",
    "# gsearch = GridSearchCV(XGBClassifier(learning_rate=0.05,n_estimators=90),parameters,cv=5,scoring='roc_auc')\n",
    "# gsearch.fit(xtr,np.array(ytr).ravel())\n",
    "# print(gsearch.best_params_)\n",
    "\n",
    "# xtr,xts,ytr,yts = train_test_split(Xtrs, ytr, test_size=0.33)\n",
    "# parameters ={'max_depth':[6,7,8], 'min_child_weight':[4,5,6]}\n",
    "# gsearch = GridSearchCV(XGBClassifier(learning_rate=0.05, n_estimators=90),parameters,cv=5,scoring='roc_auc')\n",
    "# gsearch.fit(xtr,np.array(ytr).ravel())\n",
    "# print(gsearch.best_params_)\n",
    "\n",
    "# xtr,xts,ytr,yts = train_test_split(Xtrs, ytr, test_size=0.33)\n",
    "# parameters ={'gamma':[i/10.0 for i in range(0,5)]}\n",
    "# gsearch = GridSearchCV(XGBClassifier(learing_rate=0.05,max_depth=6, min_child_weight=4, n_estimators=90),parameters,cv=5,scoring='roc_auc')\n",
    "# gsearch.fit(xtr,np.array(ytr).ravel())\n",
    "# print(gsearch.best_params_)\n",
    "\n",
    "# xtr,xts,ytr,yts = train_test_split(Xtrs, ytr, test_size=0.33)\n",
    "# parameters ={'subsample':[i/10.0 for i in range(6,10)], 'colsample_bytree':[i/10.0 for i in range(6,10)]}\n",
    "# gsearch = GridSearchCV(XGBClassifier(learning_rate=0.05,max_depth=6, min_child_weight= 4, n_estimators=90,gamma=0.2),parameters,cv=5,scoring='roc_auc')\n",
    "# gsearch.fit(xtr,np.array(ytr).ravel())\n",
    "# print(gsearch.best_params_)\n",
    "\n",
    "# xtr,xts,ytr,yts = train_test_split(Xtrs, ytr, test_size=0.33)\n",
    "# parameters ={'subsample':[i/100.0 for i in range(75,100,5)], 'colsample_bytree':[i/100.0 for i in range(70,95,5)]}\n",
    "# gsearch = GridSearchCV(XGBClassifier(learning_rate=0.05,max_depth=6, min_child_weight= 4, n_estimators=90,gamma=0.2),parameters,cv=5,scoring='roc_auc')\n",
    "# gsearch.fit(xtr,np.array(ytr).ravel())\n",
    "# print(gsearch.best_params_)\n",
    "\n",
    "# xtr,xts,ytr,yts = train_test_split(Xtrs, ytr, test_size=0.33)\n",
    "# parameters ={'reg_alpha':[0.038,0.04,0.042,0.044,0.046]}\n",
    "# gsearch = GridSearchCV(XGBClassifier(learning_rate=0.05,max_depth=6, min_child_weight=4, n_estimators=90,gamma=0,colsample_bytree=0.85,subsample=0.85), parameters, cv=5, scoring='roc_auc')\n",
    "# gsearch.fit(xtr,np.array(ytr).ravel())\n",
    "# print(gsearch.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now to Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc = 0.7727\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "nfold = 5\n",
    "kf = KFold(n_splits=nfold, shuffle=True)\n",
    "auc = []\n",
    "para_mcw = []\n",
    "for train, test in kf.split(Xtrs):\n",
    "    Xtr_split = Xtrs[train,:]\n",
    "    ytr_split = ytr[train]\n",
    "    Xts_split = Xtrs[test,:]\n",
    "    yts_split = ytr[test]\n",
    "    #best param :learning_rate=0.05,max_depth=6, min_child_weight=4, n_estimators=90,gamma=0,colsample_bytree=0.85,subsample=0.85\n",
    "    model = XGBClassifier(learning_rate=0.05,max_depth=6, min_child_weight=4, n_estimators=90,gamma=0,colsample_bytree=0.85,subsample=0.85)\n",
    "    model.fit(Xtr_split, np.array(ytr_split).ravel())\n",
    "    yprob = model.predict_proba(Xts_split)\n",
    "    auci = metrics.roc_auc_score(yts_split, yprob[:, 1])\n",
    "    auc.append(auci)\n",
    "aucm = np.mean(auc)\n",
    "print('auc = {0:.4f}'.format(aucm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
